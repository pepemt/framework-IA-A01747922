                Ejecutando validaci√≥n cruzada con 10 folds en todos los datasets...                 
Fecha y hora: 2025-09-17 14:24:06
======================================================================================================================================================


######################################################################################################################################################
                                                                     IRIS DATASET                                                                     
######################################################################################################################################################


============================================================
COMPARACI√ìN: EVALUACI√ìN SIMPLE vs VALIDACI√ìN CRUZADA
============================================================

1. EVALUACI√ìN SIMPLE (Train/Test Split):

=== RandomForest ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00         9
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30


Generando gr√°fica para RandomForest...
Gr√°fica guardada como: randomforest_iris_predictions.png
Precisi√≥n del modelo RandomForest: 1.0000

=== SVM ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00         9
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30


Generando gr√°fica para SVM...
Gr√°fica guardada como: svm_iris_predictions.png
Precisi√≥n del modelo SVM: 1.0000

=== LogisticRegression ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00         9
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30


Generando gr√°fica para LogisticRegression...
Gr√°fica guardada como: logisticregression_iris_predictions.png
Precisi√≥n del modelo LogisticRegression: 1.0000

2. VALIDACI√ìN CRUZADA (10 folds):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.86666667]
Media: 0.9533 (+/- 0.1041)
Rango: [0.8667, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.93333333]
Media: 0.9600 (+/- 0.0884)
Rango: [0.8667, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.86666667]
Media: 0.9533 (+/- 0.1041)
Rango: [0.8667, 1.0000]

============================================================
RESUMEN COMPARATIVO:
============================================================
Modelo               Simple     CV Media   CV Std     Diferencia
------------------------------------------------------------
RandomForest         1.0000     0.9533     0.0521     0.0467    
SVM                  1.0000     0.9600     0.0442     0.0400    
LogisticRegression   1.0000     0.9533     0.0521     0.0467    

======================================================================================================================================================
                      COMPARACI√ìN: MODELOS BASE vs OPTIMIZADOS CON GRIDSEARCH                       
======================================================================================================================================================

1. MODELOS BASE (par√°metros por defecto):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.86666667]
Media: 0.9533 (+/- 0.1041)
Rango: [0.8667, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.93333333]
Media: 0.9600 (+/- 0.0884)
Rango: [0.8667, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [1.         1.         1.         0.93333333 0.86666667 0.93333333
 1.         1.         0.93333333 0.86666667]
Media: 0.9533 (+/- 0.1041)
Rango: [0.8667, 1.0000]

2. MODELOS OPTIMIZADOS (GridSearch):

====================================================================================================
                                      GRID SEARCH CON 10 FOLDS                                      
====================================================================================================

--- Optimizando RandomForest ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}
Mejor score: 0.9600
Mejora sobre modelo base: 0.0104

--- Optimizando SVM ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}
Mejor score: 0.9733
Mejora sobre modelo base: 0.1001

--- Optimizando LogisticRegression ---
Fitting 10 folds for each of 90 candidates, totalling 900 fits
Mejores par√°metros: {'C': 100, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga'}
Mejor score: 0.9800
Mejora sobre modelo base: 0.1122

======================================================================================================================================================
                                                                 RESUMEN COMPARATIVO:                                                                 
======================================================================================================================================================
Modelo               Base CV      Optimizado   Mejora       Mejora %    
--------------------------------------------------------------------------------
RandomForest         0.9533       0.9600       0.0067       0.70        %
SVM                  0.9600       0.9733       0.0133       1.39        %
LogisticRegression   0.9533       0.9800       0.0267       2.80        %

======================================================================================================================================================
                                                        AN√ÅLISIS DETALLADO DE HIPERPAR√ÅMETROS                                                         
======================================================================================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - RANDOMFOREST - IRIS
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
bootstrap                 True                 True                 SIN CAMBIO     
max_depth                 None                 None                 SIN CAMBIO     
min_samples_leaf          1                    2                    MODIFICADO     
min_samples_split         2                    5                    MODIFICADO     
n_estimators              100                  50                   MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 5
Par√°metros modificados: 3
Par√°metros sin cambio: 2

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ min_samples_leaf: +100.0%
  ‚Ä¢ min_samples_split: +150.0%
  ‚Ä¢ n_estimators: -50.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üå≤ RANDOM FOREST - Interpretaci√≥n de cambios:
  ‚Ä¢ n_estimators=50: Pocos √°rboles para velocidad (menor precisi√≥n)
  ‚Ä¢ max_depth=None: Sin l√≠mite de profundidad (riesgo de overfitting)
  ‚Ä¢ min_samples_split=5: Divisi√≥n agresiva (mayor flexibilidad)

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - SVM - IRIS
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  100                  MODIFICADO     
degree                    3                    2                    MODIFICADO     
gamma                     scale                scale                SIN CAMBIO     
kernel                    rbf                  linear               MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 3
Par√°metros sin cambio: 1

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: +9900.0%
  ‚Ä¢ degree: -33.3%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üéØ SVM - Interpretaci√≥n de cambios:
  ‚Ä¢ C=100: Penalizaci√≥n alta (modelo m√°s complejo, riesgo de overfitting)
  ‚Ä¢ kernel=linear: Separaci√≥n lineal (datos linealmente separables)
  ‚Ä¢ gamma=scale: Escalado autom√°tico basado en varianza

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - LOGISTICREGRESSION - IRIS
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  100                  MODIFICADO     
max_iter                  2000                 2000                 SIN CAMBIO     
penalty                   l2                   l1                   MODIFICADO     
solver                    lbfgs                saga                 MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 3
Par√°metros sin cambio: 1

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: +9900.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üìä LOGISTIC REGRESSION - Interpretaci√≥n de cambios:
  ‚Ä¢ C=100: Regularizaci√≥n d√©bil (modelo m√°s complejo)
  ‚Ä¢ penalty=l1: Lasso (elimina caracter√≠sticas irrelevantes)
  ‚Ä¢ solver=saga: Optimizado para datasets grandes

================================================================================

====================================================================================================
TABLA RESUMEN DE HIPERPAR√ÅMETROS OPTIMIZADOS - IRIS
====================================================================================================

Modelo               Mejor Score  Par√°metros Optimizados                                      
----------------------------------------------------------------------------------------------------
RandomForest         0.9600       bootstrap=True, max_depth=None, min_samples_leaf=2, ...     
SVM                  0.9733       C=100, degree=2, gamma=scale, kernel=linear                 
LogisticRegression   0.9800       C=100, max_iter=2000, penalty=l1, solver=saga               

AN√ÅLISIS DE PATRONES COMUNES                      
--------------------------------------------------
‚Ä¢ Valor promedio de C (regularizaci√≥n): 100.00
  ‚Üí Los modelos prefieren regularizaci√≥n d√©bil (modelos m√°s complejos)
‚Ä¢ Kernel SVM seleccionado: linear
  ‚Üí Los datos son linealmente separables
‚Ä¢ N√∫mero de √°rboles en Random Forest: 50
  ‚Üí Pocos √°rboles suficientes (datos simples)

====================================================================================================

######################################################################################################################################################
                                                                     WINE DATASET                                                                     
######################################################################################################################################################


============================================================
COMPARACI√ìN: EVALUACI√ìN SIMPLE vs VALIDACI√ìN CRUZADA
============================================================

1. EVALUACI√ìN SIMPLE (Train/Test Split):

=== RandomForest ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        14
           1       1.00      1.00      1.00        14
           2       1.00      1.00      1.00         8

    accuracy                           1.00        36
   macro avg       1.00      1.00      1.00        36
weighted avg       1.00      1.00      1.00        36


Generando gr√°fica para RandomForest...
Gr√°fica guardada como: randomforest_wine_predictions.png
Precisi√≥n del modelo RandomForest: 1.0000

=== SVM ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        14
           1       1.00      1.00      1.00        14
           2       1.00      1.00      1.00         8

    accuracy                           1.00        36
   macro avg       1.00      1.00      1.00        36
weighted avg       1.00      1.00      1.00        36


Generando gr√°fica para SVM...
Gr√°fica guardada como: svm_wine_predictions.png
Precisi√≥n del modelo SVM: 1.0000

=== LogisticRegression ===
Accuracy: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        14
           1       1.00      1.00      1.00        14
           2       1.00      1.00      1.00         8

    accuracy                           1.00        36
   macro avg       1.00      1.00      1.00        36
weighted avg       1.00      1.00      1.00        36


Generando gr√°fica para LogisticRegression...
Gr√°fica guardada como: logisticregression_wine_predictions.png
Precisi√≥n del modelo LogisticRegression: 1.0000

2. VALIDACI√ìN CRUZADA (10 folds):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [1.         0.94444444 1.         1.         1.         1.
 1.         0.88888889 1.         1.        ]
Media: 0.9833 (+/- 0.0711)
Rango: [0.8889, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         0.88888889 1.         1.         0.94444444 1.
 1.         1.         1.         1.        ]
Media: 0.9833 (+/- 0.0711)
Rango: [0.8889, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [1.         0.94444444 1.         0.94444444 0.94444444 1.
 1.         1.         1.         1.        ]
Media: 0.9833 (+/- 0.0509)
Rango: [0.9444, 1.0000]

============================================================
RESUMEN COMPARATIVO:
============================================================
Modelo               Simple     CV Media   CV Std     Diferencia
------------------------------------------------------------
RandomForest         1.0000     0.9833     0.0356     0.0167    
SVM                  1.0000     0.9833     0.0356     0.0167    
LogisticRegression   1.0000     0.9833     0.0255     0.0167    

======================================================================================================================================================
                      COMPARACI√ìN: MODELOS BASE vs OPTIMIZADOS CON GRIDSEARCH                       
======================================================================================================================================================

1. MODELOS BASE (par√°metros por defecto):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [1.         0.94444444 1.         1.         1.         1.
 1.         0.88888889 1.         1.        ]
Media: 0.9833 (+/- 0.0711)
Rango: [0.8889, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         0.88888889 1.         1.         0.94444444 1.
 1.         1.         1.         1.        ]
Media: 0.9833 (+/- 0.0711)
Rango: [0.8889, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [1.         0.94444444 1.         0.94444444 0.94444444 1.
 1.         1.         1.         1.        ]
Media: 0.9833 (+/- 0.0509)
Rango: [0.9444, 1.0000]

2. MODELOS OPTIMIZADOS (GridSearch):

====================================================================================================
                                      GRID SEARCH CON 10 FOLDS                                      
====================================================================================================

--- Optimizando RandomForest ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}
Mejor score: 0.9889
Mejora sobre modelo base: 0.0097

--- Optimizando SVM ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'C': 10, 'degree': 2, 'gamma': 0.001, 'kernel': 'rbf'}
Mejor score: 0.9889
Mejora sobre modelo base: 0.1260

--- Optimizando LogisticRegression ---
Fitting 10 folds for each of 90 candidates, totalling 900 fits
Mejores par√°metros: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}
Mejor score: 0.9889
Mejora sobre modelo base: 0.0697

======================================================================================================================================================
                                                                 RESUMEN COMPARATIVO:                                                                 
======================================================================================================================================================
Modelo               Base CV      Optimizado   Mejora       Mejora %    
--------------------------------------------------------------------------------
RandomForest         0.9833       0.9889       0.0056       0.56        %
SVM                  0.9833       0.9889       0.0056       0.56        %
LogisticRegression   0.9833       0.9889       0.0056       0.56        %

======================================================================================================================================================
                                                        AN√ÅLISIS DETALLADO DE HIPERPAR√ÅMETROS                                                         
======================================================================================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - RANDOMFOREST - WINE
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
bootstrap                 True                 True                 SIN CAMBIO     
max_depth                 None                 None                 SIN CAMBIO     
min_samples_leaf          1                    1                    SIN CAMBIO     
min_samples_split         2                    2                    SIN CAMBIO     
n_estimators              100                  50                   MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 5
Par√°metros modificados: 1
Par√°metros sin cambio: 4

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ n_estimators: -50.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üå≤ RANDOM FOREST - Interpretaci√≥n de cambios:
  ‚Ä¢ n_estimators=50: Pocos √°rboles para velocidad (menor precisi√≥n)
  ‚Ä¢ max_depth=None: Sin l√≠mite de profundidad (riesgo de overfitting)
  ‚Ä¢ min_samples_split=2: Divisi√≥n agresiva (mayor flexibilidad)

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - SVM - WINE
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  10                   MODIFICADO     
degree                    3                    2                    MODIFICADO     
gamma                     scale                0.001                MODIFICADO     
kernel                    rbf                  rbf                  SIN CAMBIO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 3
Par√°metros sin cambio: 1

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: +900.0%
  ‚Ä¢ degree: -33.3%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üéØ SVM - Interpretaci√≥n de cambios:
  ‚Ä¢ C=10: Penalizaci√≥n alta (modelo m√°s complejo, riesgo de overfitting)
  ‚Ä¢ kernel=rbf: Separaci√≥n no lineal (datos complejos)
  ‚Ä¢ gamma=0.001: Influencia baja de puntos cercanos (modelo simple)

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - LOGISTICREGRESSION - WINE
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  0.1                  MODIFICADO     
max_iter                  2000                 1000                 MODIFICADO     
penalty                   l2                   l2                   SIN CAMBIO     
solver                    lbfgs                saga                 MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 3
Par√°metros sin cambio: 1

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: -90.0%
  ‚Ä¢ max_iter: -50.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üìä LOGISTIC REGRESSION - Interpretaci√≥n de cambios:
  ‚Ä¢ C=0.1: Regularizaci√≥n fuerte (modelo m√°s simple)
  ‚Ä¢ penalty=l2: Ridge (reduce impacto de caracter√≠sticas)
  ‚Ä¢ solver=saga: Optimizado para datasets grandes

================================================================================

====================================================================================================
TABLA RESUMEN DE HIPERPAR√ÅMETROS OPTIMIZADOS - WINE
====================================================================================================

Modelo               Mejor Score  Par√°metros Optimizados                                      
----------------------------------------------------------------------------------------------------
RandomForest         0.9889       bootstrap=True, max_depth=None, min_samples_leaf=1, ...     
SVM                  0.9889       C=10, degree=2, gamma=0.001, kernel=rbf                     
LogisticRegression   0.9889       C=0.1, max_iter=1000, penalty=l2, solver=saga               

AN√ÅLISIS DE PATRONES COMUNES                      
--------------------------------------------------
‚Ä¢ Valor promedio de C (regularizaci√≥n): 5.05
  ‚Üí Los modelos prefieren regularizaci√≥n d√©bil (modelos m√°s complejos)
‚Ä¢ Kernel SVM seleccionado: rbf
  ‚Üí Los datos requieren separaci√≥n no lineal
‚Ä¢ N√∫mero de √°rboles en Random Forest: 50
  ‚Üí Pocos √°rboles suficientes (datos simples)

====================================================================================================

######################################################################################################################################################
                                                                BREAST CANCER DATASET                                                                 
######################################################################################################################################################


============================================================
COMPARACI√ìN: EVALUACI√ìN SIMPLE vs VALIDACI√ìN CRUZADA
============================================================

1. EVALUACI√ìN SIMPLE (Train/Test Split):

=== RandomForest ===
Accuracy: 0.9649
              precision    recall  f1-score   support

           0       0.98      0.93      0.95        43
           1       0.96      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.97      0.96      0.96       114
weighted avg       0.97      0.96      0.96       114


Generando gr√°fica para RandomForest...
Gr√°fica guardada como: randomforest_breast cancer_predictions.png
Precisi√≥n del modelo RandomForest: 0.9649

=== SVM ===
Accuracy: 0.9825
              precision    recall  f1-score   support

           0       1.00      0.95      0.98        43
           1       0.97      1.00      0.99        71

    accuracy                           0.98       114
   macro avg       0.99      0.98      0.98       114
weighted avg       0.98      0.98      0.98       114


Generando gr√°fica para SVM...
Gr√°fica guardada como: svm_breast cancer_predictions.png
Precisi√≥n del modelo SVM: 0.9825

=== LogisticRegression ===
Accuracy: 0.9737
              precision    recall  f1-score   support

           0       0.98      0.95      0.96        43
           1       0.97      0.99      0.98        71

    accuracy                           0.97       114
   macro avg       0.97      0.97      0.97       114
weighted avg       0.97      0.97      0.97       114


Generando gr√°fica para LogisticRegression...
Gr√°fica guardada como: logisticregression_breast cancer_predictions.png
Precisi√≥n del modelo LogisticRegression: 0.9737

2. VALIDACI√ìN CRUZADA (10 folds):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [0.94736842 0.98245614 0.98245614 0.87719298 0.94736842 0.98245614
 0.96491228 0.94736842 0.92982456 1.        ]
Media: 0.9561 (+/- 0.0670)
Rango: [0.8772, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         0.98245614 0.94736842 0.96491228 0.96491228 0.96491228
 1.         0.94736842 0.98245614 1.        ]
Media: 0.9754 (+/- 0.0391)
Rango: [0.9474, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [0.98245614 0.98245614 0.94736842 0.96491228 0.98245614 0.94736842
 1.         0.98245614 0.98245614 1.        ]
Media: 0.9772 (+/- 0.0353)
Rango: [0.9474, 1.0000]

============================================================
RESUMEN COMPARATIVO:
============================================================
Modelo               Simple     CV Media   CV Std     Diferencia
------------------------------------------------------------
RandomForest         0.9649     0.9561     0.0335     0.0088    
SVM                  0.9825     0.9754     0.0195     0.0070    
LogisticRegression   0.9737     0.9772     0.0176     0.0035    

======================================================================================================================================================
                      COMPARACI√ìN: MODELOS BASE vs OPTIMIZADOS CON GRIDSEARCH                       
======================================================================================================================================================

1. MODELOS BASE (par√°metros por defecto):

==================================================
VALIDACI√ìN CRUZADA CON 10 FOLDS
==================================================

--- Evaluando RandomForest ---
Puntuaciones por fold: [0.94736842 0.98245614 0.98245614 0.87719298 0.94736842 0.96491228
 0.96491228 0.94736842 0.92982456 1.        ]
Media: 0.9544 (+/- 0.0651)
Rango: [0.8772, 1.0000]

--- Evaluando SVM ---
Puntuaciones por fold: [1.         0.98245614 0.94736842 0.96491228 0.96491228 0.96491228
 1.         0.94736842 0.98245614 1.        ]
Media: 0.9754 (+/- 0.0391)
Rango: [0.9474, 1.0000]

--- Evaluando LogisticRegression ---
Puntuaciones por fold: [0.98245614 0.98245614 0.94736842 0.96491228 0.98245614 0.94736842
 1.         0.98245614 0.98245614 1.        ]
Media: 0.9772 (+/- 0.0353)
Rango: [0.9474, 1.0000]

2. MODELOS OPTIMIZADOS (GridSearch):

====================================================================================================
                                      GRID SEARCH CON 10 FOLDS                                      
====================================================================================================

--- Optimizando RandomForest ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}
Mejor score: 0.9684
Mejora sobre modelo base: 0.0148

--- Optimizando SVM ---
Fitting 10 folds for each of 216 candidates, totalling 2160 fits
Mejores par√°metros: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}
Mejor score: 0.9772
Mejora sobre modelo base: 0.0838

--- Optimizando LogisticRegression ---
Fitting 10 folds for each of 90 candidates, totalling 900 fits
Mejores par√°metros: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}
Mejor score: 0.9807
Mejora sobre modelo base: 0.0164

======================================================================================================================================================
                                                                 RESUMEN COMPARATIVO:                                                                 
======================================================================================================================================================
Modelo               Base CV      Optimizado   Mejora       Mejora %    
--------------------------------------------------------------------------------
RandomForest         0.9544       0.9684       0.0140       1.47        %
SVM                  0.9754       0.9772       0.0018       0.18        %
LogisticRegression   0.9772       0.9807       0.0035       0.36        %

======================================================================================================================================================
                                                        AN√ÅLISIS DETALLADO DE HIPERPAR√ÅMETROS                                                         
======================================================================================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - RANDOMFOREST - BREAST CANCER
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
bootstrap                 True                 False                MODIFICADO     
max_depth                 None                 10                   MODIFICADO     
min_samples_leaf          1                    1                    SIN CAMBIO     
min_samples_split         2                    2                    SIN CAMBIO     
n_estimators              100                  100                  SIN CAMBIO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 5
Par√°metros modificados: 2
Par√°metros sin cambio: 3

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ bootstrap: -100.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üå≤ RANDOM FOREST - Interpretaci√≥n de cambios:
  ‚Ä¢ n_estimators=100: Balance entre precisi√≥n y velocidad
  ‚Ä¢ max_depth=10: √Årboles poco profundos (previene overfitting)
  ‚Ä¢ min_samples_split=2: Divisi√≥n agresiva (mayor flexibilidad)

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - SVM - BREAST CANCER
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  10                   MODIFICADO     
degree                    3                    2                    MODIFICADO     
gamma                     scale                scale                SIN CAMBIO     
kernel                    rbf                  rbf                  SIN CAMBIO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 2
Par√°metros sin cambio: 2

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: +900.0%
  ‚Ä¢ degree: -33.3%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üéØ SVM - Interpretaci√≥n de cambios:
  ‚Ä¢ C=10: Penalizaci√≥n alta (modelo m√°s complejo, riesgo de overfitting)
  ‚Ä¢ kernel=rbf: Separaci√≥n no lineal (datos complejos)
  ‚Ä¢ gamma=scale: Escalado autom√°tico basado en varianza

================================================================================

================================================================================
AN√ÅLISIS DE HIPERPAR√ÅMETROS - LOGISTICREGRESSION - BREAST CANCER
================================================================================

Par√°metro                 Valor Base           Valor Optimizado     Cambio         
--------------------------------------------------------------------------------
C                         1.0                  0.1                  MODIFICADO     
max_iter                  2000                 1000                 MODIFICADO     
penalty                   l2                   l2                   SIN CAMBIO     
solver                    lbfgs                liblinear            MODIFICADO     

RESUMEN DE CAMBIOS                                
--------------------------------------------------
Total de par√°metros analizados: 4
Par√°metros modificados: 3
Par√°metros sin cambio: 1

MEJORAS NUM√âRICAS PRINCIPALES:
  ‚Ä¢ C: -90.0%
  ‚Ä¢ max_iter: -50.0%

AN√ÅLISIS ESPEC√çFICO DEL MODELO                    
--------------------------------------------------
üìä LOGISTIC REGRESSION - Interpretaci√≥n de cambios:
  ‚Ä¢ C=0.1: Regularizaci√≥n fuerte (modelo m√°s simple)
  ‚Ä¢ penalty=l2: Ridge (reduce impacto de caracter√≠sticas)
  ‚Ä¢ solver=liblinear: Optimizado para datasets peque√±os

================================================================================

====================================================================================================
TABLA RESUMEN DE HIPERPAR√ÅMETROS OPTIMIZADOS - BREAST CANCER
====================================================================================================

Modelo               Mejor Score  Par√°metros Optimizados                                      
----------------------------------------------------------------------------------------------------
RandomForest         0.9684       bootstrap=False, max_depth=10, min_samples_leaf=1, m...     
SVM                  0.9772       C=10, degree=2, gamma=scale, kernel=rbf                     
LogisticRegression   0.9807       C=0.1, max_iter=1000, penalty=l2, solver=liblinear          

AN√ÅLISIS DE PATRONES COMUNES                      
--------------------------------------------------
‚Ä¢ Valor promedio de C (regularizaci√≥n): 5.05
  ‚Üí Los modelos prefieren regularizaci√≥n d√©bil (modelos m√°s complejos)
‚Ä¢ Kernel SVM seleccionado: rbf
  ‚Üí Los datos requieren separaci√≥n no lineal
‚Ä¢ N√∫mero de √°rboles en Random Forest: 100
  ‚Üí Balance √≥ptimo entre precisi√≥n y velocidad

====================================================================================================

======================================================================================================================================================
                                                          ¬°AN√ÅLISIS COMPLETADO EXITOSAMENTE!                                                          
======================================================================================================================================================
